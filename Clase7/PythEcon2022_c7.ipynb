{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0cba9f8",
   "metadata": {},
   "source": [
    "# Clase Nº 7 (optativa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6dacef",
   "metadata": {},
   "source": [
    "**Plan de la clase:**  \n",
    "**(1)** Aprendizaje automático o _machine learning_ (con la librería `scikit-learn`)\n",
    " - Aprendizaje supervisado <br>\n",
    " - Aprendizaje no supervisado \n",
    "\n",
    "**(2)** Aprendizaje profundo o _deep learning_ (con la librería `pytorch`)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b6fd42",
   "metadata": {},
   "source": [
    "## Aprendizaje automático"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e6c347",
   "metadata": {},
   "source": [
    "En esta sección vamos a usar la librería `scikit-learn`.\n",
    "Para instalarla, basta ejecutar `conda install scikit-learn ` en la consola.\n",
    "\n",
    "`Scikit-learn` provee una serie de funcionalidades útiles para entrenar algoritmos de aprendizaje automático.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed485762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2b2ebc",
   "metadata": {},
   "source": [
    "### Aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1bad30",
   "metadata": {},
   "source": [
    "#### Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f624c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47dfca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000 # Número de observaciones\n",
    "M = 3 # Número de predictores (features)\n",
    "beta = np.random.randn(M,1) * 2 # Efecto de cada predictor en la variable \"respuesta\" (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4c0a42",
   "metadata": {},
   "source": [
    "Simulemos los \"datos\", $X$, y los efectos $\\beta$ de cada predictor en la respuesta :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a277c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 2 *(np.random.random((N,M)) - 0.5) # los \"datos\" (uniforme en [-1,1])\n",
    "print(f\"Datos (primeras 5 filas):\\n {X[:5]} \\n...\\n\")\n",
    "print(f\"Efectos:\\n{beta}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f023f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9f3c66",
   "metadata": {},
   "source": [
    "Ahora simulemos las respuestas (o \"etiquetas\") $y=X\\beta+\\epsilon$, donde $\\epsilon\\sim \\mathcal{N}(0,\\sigma^2)$.<br>\n",
    "Primero, examinemos las dimensiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e716b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.dot(beta)\n",
    "print(f\"{X.shape} * {beta.shape} = {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d825aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "ruido = np.random.randn(N,1) * sigma\n",
    "y = y + ruido\n",
    "print(\"Efectos:\\n\",beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b174d4",
   "metadata": {},
   "source": [
    "Grafiquemos los datos (marginalizando respecto a todos los predictores salvo uno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286fcde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_y_vs_xi(Xi):\n",
    "    \n",
    "    X\n",
    "    plt.scatter(X[:, Xi], y)\n",
    "    plt.xlabel(f\"$X_{Xi}$\", fontdict={\"size\":16})\n",
    "    plt.ylabel(\"Y\", fontdict={\"size\":16})\n",
    "    plt.show()\n",
    "    \n",
    "interact(\n",
    "    plot_y_vs_xi, \n",
    "    Xi={f\"X{i}\": i for i in range(M)}\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0182e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46469fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tamaño del dataset de entrenamiento: {X_train.shape[0]}\")\n",
    "print(f\"Tamaño del dataset de testeo: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5a4a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Coeficientes reales:\\t{beta[:,0]}\")\n",
    "print(f\"Coeficientes estimados:\\t{modelo.coef_[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b99de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelo.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf3061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a22cf40",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04869be1",
   "metadata": {},
   "source": [
    "### Aprendizaje no supervisado\n",
    "Como vimos, en aprendizaje no supervisado no tenemos \"etiquetas\", sino que tratamos de descubrir patrones en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f1b5b0",
   "metadata": {},
   "source": [
    "#### Clustering\n",
    "Vamos a ver un ejemplo de un algoritmo de clustering: $k$-medias ($k$-means en inglés)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047dc61",
   "metadata": {},
   "source": [
    "Primero simulemos algunos datos con una estructura de clusters subyacente. Esto lo hacemos utilizando una función de scikit-learn llamada `make_blobs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281baccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017bd62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "clustering = cluster.KMeans(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a04007",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cbf892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# etiquetas de los clusters encontrados\n",
    "print(clustering.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "  sklearn.metrics.confusion_matrix(y_pred=clustering.labels_, y_true=y)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac195cf",
   "metadata": {},
   "source": [
    "## Aprendizaje profundo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36012468",
   "metadata": {},
   "source": [
    "En esta parte vamos a ver los fundamentos del aprendizaje profundo. Vamos a ver cómo funcionan las redes neuronales convolucionales (CNNs), que es el tipo de red neuronal que se usa para procesamiento de imágenes.\n",
    "Luego vamos a implementar una red neuronal convolucional que aprende a reconocer dígitos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7812068",
   "metadata": {},
   "source": [
    "Instalar:\n",
    "```\n",
    "conda install pytorch==1.11 -c conda-forge\n",
    "conda install torchvision -c conda-forge\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2905a8c",
   "metadata": {},
   "source": [
    "### Teoría\n",
    "#### ¿Qué es una red neuronal artificial (ANN)?\n",
    "Una red neuronal artificial es un modelo matemático que se puede representar como una sucesión de _capas_ que van desde los datos de entrada ($X$) a los datos de salida ($y$, o etiquetas). Cada capa se \"comunica\" sólo con la inmediata anterior y posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b501c6e",
   "metadata": {},
   "source": [
    "![caption](figuras/NN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da39327",
   "metadata": {},
   "source": [
    "Las capas intermedias se llaman _capas ocultas_ o _latentes_. Cada neurona de una capa recibe como entrada una combinación lineal de las salidas de las neuronas de la capa anterior. \n",
    "\n",
    "Cada flecha en la figura de arriba representa el _peso_ que le damos a la neurona de la izquierda en la entrada de la neurona de la derecha.\n",
    "\n",
    "Estos pesos son los parámetros que la red \"aprende\", de la misma manera que en una regresión lineal sencilla ajustábamos pendiente y ordenada al origen de la recta.\n",
    "\n",
    "**Pregunta**: *¿Cuántos parámetros \"ajustables\" tiene la red de arriba?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc15b0f",
   "metadata": {},
   "source": [
    "#### Funciones de activación\n",
    "Como sabemos de álgebra lineal, el proceso que describimos hasta ahora equivale a multiplicar vectores por matrices sucesivas veces, es decir hacer $y = B(Ax)$.\n",
    "\n",
    "Pero esto es equivalente a multiplicar por una sola matriz $C=BA$, es decir, a no tener ninguna capa oculta!\n",
    "\n",
    "En lugar de hacer esto, para tener más flexibilidad en el tipo de comportamiento que la red captura, en cada capa utilizamos una **función de activación no lineal**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c1347",
   "metadata": {},
   "source": [
    "#### ¿Cómo entrenamos una red neuronal?\n",
    "En general usamos una técnica **iterativa** que se llama *descenso por gradiente*, donde la \"x\" es el vector de todos los parámetros de la red (la derivada se convierte en un gradiente) y la función que queremos optimizar es una medida del error que la red está cometiendo en la iteración presente. \n",
    "\n",
    "Esta función a optimizar se llama **función de pérdida** (*loss function*) o **función de costo**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436e8641",
   "metadata": {},
   "source": [
    "![caption](figuras/gradient_descent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fac024",
   "metadata": {},
   "source": [
    "Para calcular el gradiente respecto de cada uno de los parámetros, se debe aplicar la **regla de la cadena** debido a las interdependencias que hay entre las distintas neuronas de la red. La aplicación de la regla en la cadena para redes neuronales se llama **retropropagación**.\n",
    "\n",
    "En cada iteración, el valor de los pesos de la red se corrige en una cantidad dada por el gradiente de la función de pérdida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536a779",
   "metadata": {},
   "source": [
    "#### Ver también\n",
    "- [Este](https://www.youtube.com/watch?v=aircAruvnKk) es un video **muy bueno** para ganar una mejor intuición de lo que ocurre en una red neuronal.\n",
    "- Estos videos del mismo canal explican la matemática detrás de cómo se entrena una red:\n",
    "  - [Descenso por gradiente](https://www.youtube.com/watch?v=IHZwWFHWa-w)\n",
    "  - [Retropropagación](https://www.youtube.com/watch?v=Ilg3gGewQ5U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d771f322",
   "metadata": {},
   "source": [
    "Así luce una función de pérdida real (respecto a sólo dos parámetros!):\n",
    "![caption](figuras/loss_function_nn.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83140992",
   "metadata": {},
   "source": [
    "### Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce3ef3a",
   "metadata": {},
   "source": [
    "Vamos a ver cómo usar PyTorch para implementar redes neuronales.\n",
    "Para importar la librería, ejecutamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97135d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dadefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"La versión de PyTorch que tengo instalada es la %s.\" % (torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd49163",
   "metadata": {},
   "source": [
    "¿Cómo hacemos para generar la red neuronal de más arriba?\n",
    "\n",
    "Primero, definamos la **arquitectura** de la red neuronal: 2 neuronas de entrada, 1 capa oculta con 3 neuronas y 2 neuronas de salida.\n",
    "\n",
    "Para ello tenemos que construir una clase que _herede_ de `nn.Module`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558b32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NuestraPrimeraRed(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NuestraPrimeraRed, self).__init__()\n",
    "        self.capa12 = nn.Linear(2, 3)\n",
    "        self.capa23 = nn.Linear(3, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.capa12(x)\n",
    "        x = F.sigmoid(x)\n",
    "        y = self.capa23(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0668ddd1",
   "metadata": {},
   "source": [
    "Listo!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf26d32",
   "metadata": {},
   "source": [
    "Ahora podemos inicializar el modelo, llamando al constructor de la clase:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4eb73",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo vamos a ver cómo entrenaríamos una red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaea04c",
   "metadata": {},
   "source": [
    "#### Redes neuronales convolucionales (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f1bc0",
   "metadata": {},
   "source": [
    "Las CNNs se basan en el uso de **filtros convolucionales**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bc72b7",
   "metadata": {},
   "source": [
    "Por ejemplo, este filtro produce una nueva imagen que resalta los bordes horizontales:\n",
    "<img src=\"figuras/filtro_convolucional.png\" alt=\"Drawing\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ee961",
   "metadata": {},
   "source": [
    "![caption](figuras/cnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296add61",
   "metadata": {},
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9244cf60",
   "metadata": {},
   "source": [
    "Vamos a trabajar con un dataset llamado **MNIST**, el cual contiene imágenes de dígitos de 28x28 píxeles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d362e0fb",
   "metadata": {},
   "source": [
    "Para bajarlo, podemos usar PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa421ec",
   "metadata": {},
   "source": [
    "(En [este link](https://pytorch.org/docs/stable/torchvision/datasets.html) van a poder encontrar otros datasets.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9840706",
   "metadata": {},
   "source": [
    "Examinemos un poco los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mnist_trainset.classes)\n",
    "print(mnist_trainset.train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b6aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualicemos las imágenes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig=plt.figure(figsize=(20, 10))\n",
    "for i in range(1, 16):\n",
    "    img = transforms.ToPILImage(mode='L')(mnist_trainset[i][0])\n",
    "    fig.add_subplot(1, 16, i)\n",
    "    plt.title(mnist_trainset[i][1])\n",
    "    plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbfa731",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mnist_trainset.data.shape)\n",
    "print(mnist_trainset.data[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20308e6a",
   "metadata": {},
   "source": [
    "### Preparemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "mnist_valset, mnist_testset = torch.utils.data.random_split(mnist_testset, [int(0.9 * len(mnist_testset)), int(0.1 * len(mnist_testset))])\n",
    "\n",
    "# para traernos un subconjuntos de los datos\n",
    "train_dataloader = torch.utils.data.DataLoader(Subset(mnist_trainset, range(5000)), batch_size=64, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(Subset(mnist_valset, range(1000)), batch_size=32, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(Subset(mnist_testset, range(500)), batch_size=32, shuffle=False)\n",
    "\n",
    "#train_dataloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=64, shuffle=True)\n",
    "#val_dataloader = torch.utils.data.DataLoader(mnist_valset, batch_size=32, shuffle=False)\n",
    "#test_dataloader = torch.utils.data.DataLoader(mnist_testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f165db79",
   "metadata": {},
   "source": [
    "0) Definamos la arquitectura de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0842a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NuestraSegundaRed(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NuestraSegundaRed, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8241ea66",
   "metadata": {},
   "source": [
    "1) Inicializamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = NuestraSegundaRed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5820c49",
   "metadata": {},
   "source": [
    "1) Definimos la **función de pérdida**. En este caso usamos la *entropía cruzada* (`CrossEntropyLoss`), que es la forma estándar de medir el error cuando la salida es una variable categórica (en lugar de una continua):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bb52ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterio = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d4a32",
   "metadata": {},
   "source": [
    "2) Definimos el algoritmo que vamos a usar para entrenar la red (el **optimizador**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd2517",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizador = torch.optim.Adam(modelo.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548224b",
   "metadata": {},
   "source": [
    "### Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46701af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_epochs = 5\n",
    "train_loss = list()\n",
    "val_loss = list()\n",
    "best_val_loss = 1\n",
    "\n",
    "for epoch in range(no_epochs):\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "\n",
    "    modelo.train()\n",
    "\n",
    "    # training\n",
    "    for itr, (image, label) in enumerate(train_dataloader):\n",
    "        optimizador.zero_grad()\n",
    "\n",
    "        pred = modelo(image)\n",
    "\n",
    "        loss = criterio(pred, label)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizador.step()\n",
    "\n",
    "    total_train_loss = total_train_loss / (itr + 1)\n",
    "    train_loss.append(total_train_loss)\n",
    "    \n",
    "    # validation\n",
    "    modelo.eval()\n",
    "    total = 0\n",
    "    for itr, (image, label) in enumerate(val_dataloader):\n",
    "        pred = modelo(image)\n",
    "\n",
    "        loss = criterio(pred, label)\n",
    "        total_val_loss += loss.item()\n",
    "\n",
    "        pred = torch.nn.functional.softmax(pred, dim=1)\n",
    "        for i, p in enumerate(pred):\n",
    "            if label[i] == torch.max(p.data, 0)[1]:\n",
    "                total = total + 1\n",
    "\n",
    "    accuracy = total / len(mnist_valset)\n",
    "\n",
    "    total_val_loss = total_val_loss / (itr + 1)\n",
    "    val_loss.append(total_val_loss)\n",
    "\n",
    "    hora = time.strftime(\"%H:%M:%S\") \n",
    "    print('\\n{} - Epoch: {}/{}, Train Loss: {:.8f}, Val Loss: {:.8f}, Val Accuracy: {:.8f}'.format(hora, epoch + 1, no_epochs, total_train_loss, total_val_loss, accuracy))\n",
    "\n",
    "    if total_val_loss < best_val_loss:\n",
    "        best_val_loss = total_val_loss\n",
    "        print(\"Saving the model state dictionary for Epoch: {} with Validation loss: {:.8f}\".format(epoch + 1, total_val_loss))\n",
    "        torch.save(modelo.state_dict(), \"checkpoints/model.dth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34367a19",
   "metadata": {},
   "source": [
    "Podemos cargar los parámetros del modelo ya entrenado desde el archivo que guardamos en la celda de arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e5b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.load_state_dict(torch.load(\"checkpoints/model_preentrenado.dth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5b7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(archivo):\n",
    "    a = PIL.Image.open(archivo)\n",
    "    a = np.asarray(a)\n",
    "    a = torch.Tensor(a)\n",
    "    a = a.expand(1,1,28,28)\n",
    "    print(modelo(a).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b018d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd93fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(f, archivo=widgets.Dropdown(options=[x for x in os.listdir() if x.endswith(\"png\")]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a64c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig=plt.figure(figsize=(20, 10))\n",
    "plt.plot(np.arange(1, no_epochs+1), train_loss, label=\"Train loss\")\n",
    "plt.plot(np.arange(1, no_epochs+1), val_loss, label=\"Validation loss\")\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Epochs')\n",
    "plt.title(\"Loss Plots\")\n",
    "plt.legend(loc='upper right')\n",
    "# plt.show()\n",
    "plt.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6755d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
